swe_1d_don_obs_01.npz
用高斯函数作为初值，以数值解为基础，从中选取 [0,0.1,0.2,...,1]*[0,0.1,0.2,...,1] 的网格点,作为观测，
数值解是401*401进行的，一组观测对应的网格点是11*11=121，因为每个点对应两个观测值：高度和速度；所以一组观测的长度是242。
高斯函数为：0.1 + 0.1 * np.exp(-64 * (x - mu[:, None]) ** 2) ，mu的取值为[0,0.01,0.02,...,1] 共101个；
所以最后攻101组观测；

swe_1d_don_obs_01.py
网络层数
区间长度[0,1]*[0,1]
101组观测，每组观测121个点，物理点选取1000个；
obs dataset size (mb): 0.00020599365234375
physics dataset size (mb): 0.0001373291015625
obs_ds count: 12221 physics_ds count: 101000

swe_1d_don_obs_01_1.5e-5.pt 区间长度[0,1]*[0,1]  mse<1.5e-5 Elapsed time:  3:08:55.065380
swe_1d_don_obs_01_e-5.pt 区间长度[0,1]*[0,1] mse<1e-5 batch : 155628 lr : 3.125e-05 loss : 9.754292477737181e-06 Elapsed time:  6:17:37.794513

swe_1d_don_obs_04.py
网络层数：
[o_train.shape[1], 128, 64, 64, 64, 64]
[y_train.shape[1], 64, 64, 64, 64, 64]
由于mse多轮训练，一直降不下来，怀疑是物理点选取的少了，所以改为5000个：(其他和swe_1d_don_obs_01.py一致)
swe_1d_don_obs_04_e-5.pt batch : 166840 lr : 0.00025 loss : 9.756658073456492e-06 Elapsed time:  6:28:12.704971
改变网络层数： 暂时还没训练
[o_train.shape[1], 200, 150, 100, 64, 64, 64, 64, 64]
[y_train.shape[1], 64, 64, 64, 64, 64, 64, 64, 64]

swe_1d_don_obs_05.py
相对于swe_1d_don_obs_04.py，把时间跨度缩短为[0,0.5]，物理信息点为5000个
swe_1d_don_obs_05_5e-6.pt batch : 42849 lr : 0.001 loss : 4.992206413589884e-06 Elapsed time:  1:45:23.684916

+++++++++++++++++++++++++++++++ 非主流程
swe_1d_don_obs_02.py
与swe_1d_don_obs_01.py 相同的逻辑，只是训练集是实时生成，不是一次性初始化到内存或GPU。
不过基础数据是初始化到gpu里面的，训练的时候，是根据gpu里面的基础数据，根据规则，实时生成训练数据。
这对于大数据集训练很有用，所以验证下代码的正确性。
swe_1d_don_obs_02_1.5e-5.pt batch : 94392 lr : 0.0005 loss : 1.4726610970683396e-05 Elapsed time:  11:11:41.842465
测试结果表明，代码正确。

swe_1d_don_obs_03.py
与swe_1d_don_obs_01.py 相同的逻辑，只是训练集是一次性初始化到内存，而不是GPU。在每次训练的时候，是把内存的数据搬到GPU。
这对于大数据集训练很有用，所以验证下代码的正确性。
同样的到mse到1.5e-5时，2023-06-16 01:16:49.984957 batch : 90900 lr : 0.001 loss : 1.4950130207580514e-05
时间大概为：25h18m
++++++++++++++++++++++++++++++