lorenz63_data_chaos.py
使用RK方法，[1.508870, -1.531271, 25.46091]为初值，生成混沌的数值解，时间区间[0,14.995]，保存到文件 lorenz63_chaos.npy

lorenz63_data_non_chaos.py
使用RK方法，[-4., 7., 15]为初值，生成非混沌的数值解，时间区间[0,14.995]，
保存到文件 lorenz63_non_chaos.npy

lorenz63_don_01.py
考虑的是非混沌情形（rho=15），用的原始的DeepONet架构，训练的时间区间[0,0.5]，
使用高斯核函数进行密度估计，得到样本密度函数，然后随机生成初值点10000个，作为训练数据。
物理配点等距取100个，
lorenz63_don_01_05_gzz_01.pt 是训练出的最好的模型
在测试模块lorenz63_don_01_test.py 中使用种子数 np.random.seed(123)，可以得到较好的结果；

lorenz63_don_02.py
考虑的是混沌情形（rho=28），直接采用数值解作为训练样本。用的原始的DeepONet架构，代码复用，训练的时间区间分别是[0,0.1]和[0,0.2]，
物理配点等距取40个，
lorenz63_don_02_01_-1_gzz_01.pt
后缀中的01应该表示训练区间长度0.1，-1表示训练条件是loss达到10^{-1}，gzz表示工作站的训练结果。
其他pt文件亦然。
当训练区间为[0,0.2]的时候，整体来说不理想，一来是 训练的数据不是由密度函数随机采样，二来测试的误差较大。
当训练期间为[0,0.1]的时候，效果还行，lorenz63_don_02_test2.py + lorenz63_don_02_01_-1_gzz_non_random.pt测试
相对误差到了1%的量级，但与非混沌情形的误差效果还差不少。而且训练的数据不是由密度函数随机采样
（注：lorenz63_don_02_01_-1_gzz_non_random.pt 和 lorenz63_don_02_01_-2_gzz_non_random.pt 根据测试，应该是同一个模型，不记得当初为什么命名两个文件）

lorenz63_don_03.py
考虑的是混沌情形（rho=28），代码复用，训练的时间区间分别是[0,0.1]和[0,0.2]，
物理配点等距取40个，最后一层激活函数用sin，
使用高斯核函数进行密度估计，得到样本密度函数，然后随机生成初值点10000个，作为训练数据。
测试效果，都不好。PASS

